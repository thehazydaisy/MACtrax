import requests
from bs4 import BeautifulSoup
import re

def parse_mac_addresses_and_dates(urls, output_file):
    with open(output_file, 'w', encoding='utf-8') as f:
        for url in urls:
            try:
                response = requests.get(url)
                response.raise_for_status()

                soup = BeautifulSoup(response.content, 'html.parser')

                mac_addresses = soup.find_all('code', string=re.compile(r'(?:[0-9A-Fa-f]{2}:){5}[0-9A-Fa-f]{2}'))

                for mac_address_code in mac_addresses:
                    mac_address = mac_address_code.string.strip()

                    td = mac_address_code.find_parent('td')
                    if td:
                        url_element = td.find('a', href=True)
                        if url_element:
                            closest_url = url_element['href']
                            f.write(closest_url + '\n')

                    closest_date = None
                    for sibling in mac_address_code.next_siblings:
                        if isinstance(sibling, NavigableString):
                            date_match = re.search(r'\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{1,2},\s+\d{4}\b', sibling)
                            if date_match:
                                closest_date = date_match.group(0)
                                break

                    if closest_date:
                        f.write(f"{mac_address} {closest_date}\n")
                    else:
                        f.write(mac_address + '\n')

                    f.write('\n') 

            except requests.exceptions.RequestException as e:
                print(f"Error processing URL {url}: {e}")